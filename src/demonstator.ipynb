{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "import time\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yolo model\n",
    "model = YOLO('glasses_v2_640.pt', task='detect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ear(eye_landmarks):\n",
    "    # EAR = (||P2 - P6|| + ||P3 - P5||) / (2 * ||P1 - P4||)\n",
    "    #vertical\n",
    "    A = np.linalg.norm(np.array([eye_landmarks[1].x, eye_landmarks[1].y]) - np.array([eye_landmarks[5].x, eye_landmarks[5].y]))\n",
    "    B = np.linalg.norm(np.array([eye_landmarks[2].x, eye_landmarks[2].y]) - np.array([eye_landmarks[4].x, eye_landmarks[4].y]))\n",
    "    #horizontal\n",
    "    C = np.linalg.norm(np.array([eye_landmarks[0].x, eye_landmarks[0].y]) - np.array([eye_landmarks[3].x, eye_landmarks[3].y]))\n",
    "    #eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glasses Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 816.6ms\n",
      "Speed: 19.2ms preprocess, 816.6ms inference, 15.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "no_detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 848.2ms\n",
      "Speed: 11.0ms preprocess, 848.2ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 717.2ms\n",
      "Speed: 3.0ms preprocess, 717.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 827.0ms\n",
      "Speed: 3.0ms preprocess, 827.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 854.0ms\n",
      "Speed: 3.0ms preprocess, 854.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 850.9ms\n",
      "Speed: 4.0ms preprocess, 850.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 687.2ms\n",
      "Speed: 5.0ms preprocess, 687.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 633.5ms\n",
      "Speed: 0.0ms preprocess, 633.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 666.9ms\n",
      "Speed: 3.0ms preprocess, 666.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 593.2ms\n",
      "Speed: 4.7ms preprocess, 593.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 609.5ms\n",
      "Speed: 2.0ms preprocess, 609.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 760.5ms\n",
      "Speed: 4.7ms preprocess, 760.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 656.3ms\n",
      "Speed: 3.0ms preprocess, 656.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 602.6ms\n",
      "Speed: 2.0ms preprocess, 602.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 631.8ms\n",
      "Speed: 3.6ms preprocess, 631.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 591.3ms\n",
      "Speed: 3.0ms preprocess, 591.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 762.9ms\n",
      "Speed: 3.0ms preprocess, 762.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_with_glasses\n"
     ]
    }
   ],
   "source": [
    "# test if glasses detection works\n",
    "cap = cv2.VideoCapture(0) # 0 for webcam\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Fehler beim Ã–ffnen der Kamera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Fehler beim Erfassen des Frames\")\n",
    "        break\n",
    "\n",
    "    results = model(frame, conf=0.4) \n",
    "    \n",
    "    detected_objects = results[0].boxes.cls \n",
    "    if len(detected_objects) == 0:\n",
    "        print(\"no_detection\")\n",
    "    else:\n",
    "        for detected_object in detected_objects: # 0 = face_with_glasses, 1 = face_without_glasses\n",
    "            if detected_object.item() == 0:\n",
    "                print(\"face_with_glasses\")\n",
    "            elif detected_object.item() == 1:\n",
    "                print(\"face_without_glasses\")\n",
    "            else:\n",
    "                print(\"no_object\")\n",
    "        \n",
    "    annotated_frame = results[0].plot() # plot the detected objects\n",
    "\n",
    "    cv2.imshow('YOLOv8 Predictions', annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blink Detection:\n",
    "When a person is in the drowsy state, the total number of eye blinks in a minute decreases. https://core.ac.uk/download/pdf/328811514.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classes\n",
    "detected_object1 = 'face_without_glasses'\n",
    "detected_object2 = 'face_with_glasses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if blink detection works\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Eye landmarks\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]  # P1=33, P2=160, P3=158, P4=133, P5=153, P6=144\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # P1=362, P2=385, P3=387, P4=263, P5=373, P6=380\n",
    "\n",
    "# Threshold for blinking\n",
    "if detected_object1 == 'face_without_glasses':\n",
    "    treshhold = 0.25\n",
    "elif detected_object1 == 'face_with_glasses':\n",
    "    treshhold = 0.005\n",
    "else:\n",
    "    treshhold = 0.05\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "blink_count = 0\n",
    "last_blink_time = time.time()\n",
    "no_blink_start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks: \n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            left_eye_landmarks = [face_landmarks.landmark[idx] for idx in LEFT_EYE]\n",
    "            right_eye_landmarks = [face_landmarks.landmark[idx] for idx in RIGHT_EYE]\n",
    "\n",
    "            left_ear = calculate_ear(left_eye_landmarks)\n",
    "            right_ear = calculate_ear(right_eye_landmarks)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            for idx in LEFT_EYE + RIGHT_EYE:\n",
    "                x = int(face_landmarks.landmark[idx].x * frame.shape[1])\n",
    "                y = int(face_landmarks.landmark[idx].y * frame.shape[0])\n",
    "                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "\n",
    "            if ear < treshhold:  # threshold for blinking\n",
    "                cv2.putText(frame, \"Blinking\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                blink_count += 1\n",
    "                last_blink_time = time.time()\n",
    "                no_blink_start_time = time.time()  # Reset the no blink timer\n",
    "\n",
    "    # Check if 10 seconds have passed without blinking\n",
    "    if time.time() - last_blink_time > 10:\n",
    "        cv2.putText(frame, \"Not allowed to drive\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('Eye Landmarks', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blink+glasses Detection: (need gpu, because glasses detection is every frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 face_with_glasses, 663.7ms\n",
      "Speed: 6.0ms preprocess, 663.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 796.2ms\n",
      "Speed: 9.0ms preprocess, 796.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 658.9ms\n",
      "Speed: 3.0ms preprocess, 658.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 591.2ms\n",
      "Speed: 3.0ms preprocess, 591.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 591.6ms\n",
      "Speed: 2.0ms preprocess, 591.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 607.9ms\n",
      "Speed: 3.0ms preprocess, 607.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 613.9ms\n",
      "Speed: 3.1ms preprocess, 613.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 627.1ms\n",
      "Speed: 3.0ms preprocess, 627.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 678.9ms\n",
      "Speed: 3.0ms preprocess, 678.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 688.4ms\n",
      "Speed: 2.0ms preprocess, 688.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 627.5ms\n",
      "Speed: 3.0ms preprocess, 627.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 584.0ms\n",
      "Speed: 4.0ms preprocess, 584.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 621.2ms\n",
      "Speed: 2.7ms preprocess, 621.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]  # P1=33, P2=160, P3=158, P4=133, P5=153, P6=144\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # P1=362, P2=385, P3=387, P4=263, P5=373, P6=380\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Fehler beim Ã–ffnen der Kamera\")\n",
    "    exit()\n",
    "\n",
    "detected_object = None\n",
    "blink_count = 0\n",
    "last_blink_time = time.time()\n",
    "no_blink_start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Fehler beim Erfassen des Frames\")\n",
    "        break\n",
    "\n",
    "    # detect glasses    \n",
    "    results = model(frame, conf=0.4) \n",
    "    detected_objects = results[0].boxes.cls\n",
    "    if len(detected_objects) == 0:\n",
    "        detected_object = 'no_detection'\n",
    "    else:\n",
    "        for detected_object in detected_objects:\n",
    "            if detected_object.item() == 0:\n",
    "                detected_object = 'face_with_glasses'\n",
    "            elif detected_object.item() == 1:\n",
    "                detected_object = 'face_without_glasses'\n",
    "            else:\n",
    "                detected_object = 'no_object'\n",
    "        if detected_object == 'face_without_glasses':\n",
    "            treshhold = 0.25\n",
    "        elif detected_object == 'face_with_glasses':\n",
    "            treshhold = 0.005\n",
    "        else:\n",
    "            treshhold = 0.05\n",
    "    # detect eye landmarks\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            left_eye_landmarks = [face_landmarks.landmark[idx] for idx in LEFT_EYE]\n",
    "            right_eye_landmarks = [face_landmarks.landmark[idx] for idx in RIGHT_EYE]\n",
    "\n",
    "            left_ear = calculate_ear(left_eye_landmarks)\n",
    "            right_ear = calculate_ear(right_eye_landmarks)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            for idx in LEFT_EYE + RIGHT_EYE:\n",
    "                x = int(face_landmarks.landmark[idx].x * frame.shape[1])\n",
    "                y = int(face_landmarks.landmark[idx].y * frame.shape[0])\n",
    "                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "\n",
    "            if ear < treshhold:  \n",
    "                cv2.putText(frame, \"Blinking\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                blink_count += 1\n",
    "                last_blink_time = time.time()\n",
    "                no_blink_start_time = time.time()\n",
    "\n",
    "\n",
    "    if time.time() - last_blink_time > 10:\n",
    "        cv2.putText(frame, \"Not allowed to drive\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('YOLOv8 Predictions and Eye Landmarks', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blink+glasses Detection: (better FPS, because glasses detection only every 10 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 753.5ms\n",
      "Speed: 7.0ms preprocess, 753.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 618.9ms\n",
      "Speed: 3.0ms preprocess, 618.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 600.7ms\n",
      "Speed: 2.0ms preprocess, 600.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 630.0ms\n",
      "Speed: 2.0ms preprocess, 630.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 614.3ms\n",
      "Speed: 2.0ms preprocess, 614.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 669.0ms\n",
      "Speed: 2.0ms preprocess, 669.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 698.8ms\n",
      "Speed: 5.0ms preprocess, 698.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 658.3ms\n",
      "Speed: 4.0ms preprocess, 658.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# define EAR (faster apply)\n",
    "def calculate_ear(eye_landmarks):\n",
    "    A = ((eye_landmarks[1][0] - eye_landmarks[5][0]) ** 2 + (eye_landmarks[1][1] - eye_landmarks[5][1]) ** 2) ** 0.5\n",
    "    B = ((eye_landmarks[2][0] - eye_landmarks[4][0]) ** 2 + (eye_landmarks[2][1] - eye_landmarks[4][1]) ** 2) ** 0.5\n",
    "    C = ((eye_landmarks[0][0] - eye_landmarks[3][0]) ** 2 + (eye_landmarks[0][1] - eye_landmarks[3][1]) ** 2) ** 0.5\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]  # P1=33, P2=160, P3=158, P4=133, P5=153, P6=144\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # P1=362, P2=385, P3=387, P4=263, P5=373, P6=380\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Fehler beim Ã–ffnen der Kamera\")\n",
    "    exit()\n",
    "\n",
    "detected_object = None\n",
    "blink_count = 0\n",
    "last_blink_time = time.time()\n",
    "no_blink_start_time = time.time()\n",
    "last_glasses_check_time = time.time()\n",
    "glasses_check_interval = 5\n",
    "treshhold = 0.15\n",
    "\n",
    "# glasses detection\n",
    "def detect_glasses(frame):\n",
    "    results = model(frame, conf=0.4)\n",
    "    detected_objects = results[0].boxes\n",
    "\n",
    "    if len(detected_objects) == 0:\n",
    "        return 'no_detection'\n",
    "    else:\n",
    "        closest_object = None\n",
    "        max_area = 0\n",
    "\n",
    "        for detected_object in detected_objects:\n",
    "            box = detected_object.xyxy[0]\n",
    "            area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                closest_object = detected_object\n",
    "\n",
    "        if closest_object:\n",
    "            if closest_object.cls.item() == 0:\n",
    "                return 'face_with_glasses'\n",
    "            elif closest_object.cls.item() == 1:\n",
    "                return 'face_without_glasses'\n",
    "            else:\n",
    "                return 'no_object'\n",
    "        else:\n",
    "            return 'no_object'\n",
    "\n",
    "# blink detection\n",
    "def detect_blinks(frame):\n",
    "    global blink_count, last_blink_time, treshhold\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            left_eye_landmarks = [(face_landmarks.landmark[idx].x * frame.shape[1], \n",
    "                                   face_landmarks.landmark[idx].y * frame.shape[0]) for idx in LEFT_EYE]\n",
    "            right_eye_landmarks = [(face_landmarks.landmark[idx].x * frame.shape[1], \n",
    "                                    face_landmarks.landmark[idx].y * frame.shape[0]) for idx in RIGHT_EYE]\n",
    "\n",
    "            left_ear = calculate_ear(left_eye_landmarks)\n",
    "            right_ear = calculate_ear(right_eye_landmarks)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            if ear < treshhold:\n",
    "                cv2.putText(frame, \"Blinking\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                blink_count += 1\n",
    "                last_blink_time = time.time()\n",
    "\n",
    "    if time.time() - last_blink_time > 10:\n",
    "        cv2.putText(frame, \"Not allowed to drive\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "# process the frame with glasses detection and blink detection\n",
    "def process_frame():\n",
    "    global last_glasses_check_time, treshhold\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Fehler beim Erfassen des Frames\")\n",
    "            break\n",
    "\n",
    "        detect_blinks(frame)\n",
    "        \n",
    "        current_time = time.time()\n",
    "        if current_time - last_glasses_check_time > glasses_check_interval:\n",
    "            print(f\"Glasses Detection\")\n",
    "            last_glasses_check_time = current_time\n",
    "\n",
    "            glasses_status = detect_glasses(frame)\n",
    "            if glasses_status == 'face_with_glasses':\n",
    "                treshhold = 0.05 \n",
    "            elif glasses_status == 'face_without_glasses':\n",
    "                treshhold = 0.20 \n",
    "            else:\n",
    "                treshhold = 0.15\n",
    "\n",
    "        cv2.imshow('YOLOv8 Predictions and Eye Landmarks', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "processing_thread = threading.Thread(target=process_frame)\n",
    "processing_thread.start()\n",
    "processing_thread.join()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrator save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leo\\Desktop\\AI\\fairness_demonstator\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 699.0ms\n",
      "Speed: 7.0ms preprocess, 699.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 613.7ms\n",
      "Speed: 3.0ms preprocess, 613.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 611.4ms\n",
      "Speed: 3.0ms preprocess, 611.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 596.5ms\n",
      "Speed: 3.0ms preprocess, 596.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 612.3ms\n",
      "Speed: 4.0ms preprocess, 612.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 609.8ms\n",
      "Speed: 3.2ms preprocess, 609.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 626.2ms\n",
      "Speed: 3.5ms preprocess, 626.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=2, \n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]  # P1=33, P2=160, P3=158, P4=133, P5=153, P6=144\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # P1=362, P2=385, P3=387, P4=263, P5=373, P6=380\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Fehler beim Ã–ffnen der Kamera\")\n",
    "    exit()\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'XVID'), 20, (frame_width, frame_height))\n",
    "\n",
    "detected_object = None\n",
    "blink_count = 0\n",
    "last_blink_time = time.time()\n",
    "no_blink_start_time = time.time()\n",
    "last_glasses_check_time = time.time()\n",
    "glasses_check_interval = 5\n",
    "treshhold = 0.15\n",
    "\n",
    "# save frames as video (output.avi)\n",
    "def process_frame_save():\n",
    "    global last_glasses_check_time, treshhold\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Fehler beim Erfassen des Frames\")\n",
    "            break\n",
    "\n",
    "        detect_blinks(frame)\n",
    "        \n",
    "        current_time = time.time()\n",
    "        if current_time - last_glasses_check_time > glasses_check_interval:\n",
    "            print(f\"Glasses Detection\")\n",
    "            last_glasses_check_time = current_time\n",
    "\n",
    "            glasses_status = detect_glasses(frame)\n",
    "            if glasses_status == 'face_with_glasses':\n",
    "                treshhold = 0.05 \n",
    "            elif glasses_status == 'face_without_glasses':\n",
    "                treshhold = 0.20 \n",
    "            else:\n",
    "                treshhold = 0.15\n",
    "\n",
    "        cv2.imshow('YOLOv8 Predictions and Eye Landmarks', frame)\n",
    "        out.write(frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "processing_thread = threading.Thread(target=process_frame_save)\n",
    "processing_thread.start()\n",
    "processing_thread.join()\n",
    "\n",
    "cap.release()\n",
    "out.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
