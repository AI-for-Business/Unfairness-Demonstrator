{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "import time\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glasses Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('glasses_v2_640.pt', task='detect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\Leo\\Desktop\\AI\\fairness_demonstator\\image_03.jpg: 384x640 1 face_with_glasses, 1642.4ms\n",
      "Speed: 8.1ms preprocess, 1642.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 c:\\Users\\Leo\\Desktop\\AI\\fairness_demonstator\\image_06.jpg: 384x640 1 face_without_glasses, 1045.8ms\n",
      "Speed: 13.7ms preprocess, 1045.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "result1 = model(\"image_03.jpg\", conf=0.4)\n",
    "result2 = model(\"image_06.jpg\", conf=0.4)\n",
    "\n",
    "# results = model(\"image_06.jpg\", conf=0.4)\n",
    "# annotated_image = results[0].plot()\n",
    "\n",
    "# cv2.imshow('glasses_detection', annotated_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 face_without_glasses, 1178.9ms\n",
      "Speed: 6.0ms preprocess, 1178.9ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_without_glasses\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 1763.6ms\n",
      "Speed: 14.1ms preprocess, 1763.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_without_glasses\n",
      "\n",
      "0: 480x640 2 face_without_glassess, 2246.6ms\n",
      "Speed: 11.0ms preprocess, 2246.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_without_glasses\n",
      "face_without_glasses\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 1283.3ms\n",
      "Speed: 31.5ms preprocess, 1283.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_without_glasses\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 1030.1ms\n",
      "Speed: 2.0ms preprocess, 1030.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_without_glasses\n",
      "\n",
      "0: 480x640 2 face_without_glassess, 722.2ms\n",
      "Speed: 4.0ms preprocess, 722.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_without_glasses\n",
      "face_without_glasses\n",
      "\n",
      "0: 480x640 2 face_without_glassess, 752.5ms\n",
      "Speed: 2.0ms preprocess, 752.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_without_glasses\n",
      "face_without_glasses\n",
      "\n",
      "0: 480x640 2 face_without_glassess, 686.7ms\n",
      "Speed: 4.0ms preprocess, 686.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "face_without_glasses\n",
      "face_without_glasses\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Fehler beim Ã–ffnen der Kamera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Fehler beim Erfassen des Frames\")\n",
    "        break\n",
    "\n",
    "    results = model(frame, conf=0.4)\n",
    "    \n",
    "    detected_objects = results[0].boxes.cls\n",
    "    if len(detected_objects) == 0:\n",
    "        print(\"no_detection\")\n",
    "    else:\n",
    "        for detected_object in detected_objects:\n",
    "            if detected_object.item() == 0:\n",
    "                print(\"face_with_glasses\")\n",
    "            elif detected_object.item() == 1:\n",
    "                print(\"face_without_glasses\")\n",
    "            else:\n",
    "                print(\"no_object\")\n",
    "        \n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    cv2.imshow('YOLOv8 Predictions', annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blink Detection:\n",
    "When a person is in the drowsy state, the total number of eye blinks in a minute decreases. https://core.ac.uk/download/pdf/328811514.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ear(eye_landmarks):\n",
    "    # EAR = (||P2 - P6|| + ||P3 - P5||) / (2 * ||P1 - P4||)\n",
    "    #vertical\n",
    "    A = np.linalg.norm(np.array([eye_landmarks[1].x, eye_landmarks[1].y]) - np.array([eye_landmarks[5].x, eye_landmarks[5].y]))\n",
    "    B = np.linalg.norm(np.array([eye_landmarks[2].x, eye_landmarks[2].y]) - np.array([eye_landmarks[4].x, eye_landmarks[4].y]))\n",
    "    #horizontal\n",
    "    C = np.linalg.norm(np.array([eye_landmarks[0].x, eye_landmarks[0].y]) - np.array([eye_landmarks[3].x, eye_landmarks[3].y]))\n",
    "    #eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_object1 = 'face_without_glasses'\n",
    "detected_object2 = 'face_with_glasses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]  # P1=33, P2=160, P3=158, P4=133, P5=153, P6=144\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # P1=362, P2=385, P3=387, P4=263, P5=373, P6=380\n",
    "\n",
    "if detected_object1 == 'face_without_glasses':\n",
    "    treshhold = 0.25\n",
    "elif detected_object1 == 'face_with_glasses':\n",
    "    treshhold = 0.005\n",
    "else:\n",
    "    treshhold = 0.05\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "blink_count = 0\n",
    "last_blink_time = time.time()\n",
    "no_blink_start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            left_eye_landmarks = [face_landmarks.landmark[idx] for idx in LEFT_EYE]\n",
    "            right_eye_landmarks = [face_landmarks.landmark[idx] for idx in RIGHT_EYE]\n",
    "\n",
    "            left_ear = calculate_ear(left_eye_landmarks)\n",
    "            right_ear = calculate_ear(right_eye_landmarks)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            for idx in LEFT_EYE + RIGHT_EYE:\n",
    "                x = int(face_landmarks.landmark[idx].x * frame.shape[1])\n",
    "                y = int(face_landmarks.landmark[idx].y * frame.shape[0])\n",
    "                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "\n",
    "            if ear < treshhold:  # threshold for blinking\n",
    "                cv2.putText(frame, \"Blinking\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                blink_count += 1\n",
    "                last_blink_time = time.time()\n",
    "                no_blink_start_time = time.time()  # Reset the no blink timer\n",
    "\n",
    "    # Check if 10 seconds have passed without blinking\n",
    "    if time.time() - last_blink_time > 10:\n",
    "        cv2.putText(frame, \"Not allowed to drive\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('Eye Landmarks', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blink+glasses Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 1073.7ms\n",
      "Speed: 31.0ms preprocess, 1073.7ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1157.1ms\n",
      "Speed: 3.0ms preprocess, 1157.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1033.8ms\n",
      "Speed: 3.0ms preprocess, 1033.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1187.5ms\n",
      "Speed: 3.6ms preprocess, 1187.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1256.2ms\n",
      "Speed: 3.0ms preprocess, 1256.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 779.0ms\n",
      "Speed: 3.6ms preprocess, 779.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 731.1ms\n",
      "Speed: 3.0ms preprocess, 731.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 764.2ms\n",
      "Speed: 3.0ms preprocess, 764.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 633.6ms\n",
      "Speed: 2.0ms preprocess, 633.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 778.5ms\n",
      "Speed: 3.0ms preprocess, 778.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 732.7ms\n",
      "Speed: 3.0ms preprocess, 732.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 742.8ms\n",
      "Speed: 3.0ms preprocess, 742.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 654.4ms\n",
      "Speed: 3.5ms preprocess, 654.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 616.6ms\n",
      "Speed: 2.0ms preprocess, 616.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 651.1ms\n",
      "Speed: 3.0ms preprocess, 651.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 628.6ms\n",
      "Speed: 3.0ms preprocess, 628.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 689.5ms\n",
      "Speed: 2.5ms preprocess, 689.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 673.1ms\n",
      "Speed: 3.0ms preprocess, 673.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 705.3ms\n",
      "Speed: 4.5ms preprocess, 705.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 643.5ms\n",
      "Speed: 2.0ms preprocess, 643.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]  # P1=33, P2=160, P3=158, P4=133, P5=153, P6=144\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # P1=362, P2=385, P3=387, P4=263, P5=373, P6=380\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Fehler beim Ã–ffnen der Kamera\")\n",
    "    exit()\n",
    "\n",
    "detected_object = None\n",
    "blink_count = 0\n",
    "last_blink_time = time.time()\n",
    "no_blink_start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Fehler beim Erfassen des Frames\")\n",
    "        break\n",
    "\n",
    "    results = model(frame, conf=0.4)\n",
    "    detected_objects = results[0].boxes.cls\n",
    "    if len(detected_objects) == 0:\n",
    "        detected_object = 'no_detection'\n",
    "    else:\n",
    "        for detected_object in detected_objects:\n",
    "            if detected_object.item() == 0:\n",
    "                detected_object = 'face_with_glasses'\n",
    "            elif detected_object.item() == 1:\n",
    "                detected_object = 'face_without_glasses'\n",
    "            else:\n",
    "                detected_object = 'no_object'\n",
    "        if detected_object == 'face_without_glasses':\n",
    "            treshhold = 0.25\n",
    "        elif detected_object == 'face_with_glasses':\n",
    "            treshhold = 0.005\n",
    "        else:\n",
    "            treshhold = 0.05\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            left_eye_landmarks = [face_landmarks.landmark[idx] for idx in LEFT_EYE]\n",
    "            right_eye_landmarks = [face_landmarks.landmark[idx] for idx in RIGHT_EYE]\n",
    "\n",
    "            left_ear = calculate_ear(left_eye_landmarks)\n",
    "            right_ear = calculate_ear(right_eye_landmarks)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            for idx in LEFT_EYE + RIGHT_EYE:\n",
    "                x = int(face_landmarks.landmark[idx].x * frame.shape[1])\n",
    "                y = int(face_landmarks.landmark[idx].y * frame.shape[0])\n",
    "                cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "\n",
    "            if ear < treshhold:  \n",
    "                cv2.putText(frame, \"Blinking\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                blink_count += 1\n",
    "                last_blink_time = time.time()\n",
    "                no_blink_start_time = time.time()\n",
    "\n",
    "\n",
    "    if time.time() - last_blink_time > 10:\n",
    "        cv2.putText(frame, \"Not allowed to drive\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('YOLOv8 Predictions and Eye Landmarks', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hÃ¶here FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 668.0ms\n",
      "Speed: 15.7ms preprocess, 668.0ms inference, 15.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 608.2ms\n",
      "Speed: 0.0ms preprocess, 608.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 619.8ms\n",
      "Speed: 3.1ms preprocess, 619.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 618.0ms\n",
      "Speed: 0.0ms preprocess, 618.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 615.5ms\n",
      "Speed: 0.0ms preprocess, 615.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 722.0ms\n",
      "Speed: 0.0ms preprocess, 722.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 613.5ms\n",
      "Speed: 4.5ms preprocess, 613.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 608.9ms\n",
      "Speed: 0.8ms preprocess, 608.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 1 face_without_glasses, 679.0ms\n",
      "Speed: 0.0ms preprocess, 679.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 1 face_without_glasses, 631.8ms\n",
      "Speed: 0.0ms preprocess, 631.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 1 face_without_glasses, 650.5ms\n",
      "Speed: 0.0ms preprocess, 650.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 1 face_without_glasses, 726.4ms\n",
      "Speed: 0.0ms preprocess, 726.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 2 face_without_glassess, 622.7ms\n",
      "Speed: 0.0ms preprocess, 622.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 2 face_without_glassess, 635.9ms\n",
      "Speed: 0.0ms preprocess, 635.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 2 face_without_glassess, 600.0ms\n",
      "Speed: 0.0ms preprocess, 600.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 652.4ms\n",
      "Speed: 0.0ms preprocess, 652.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 2 face_without_glassess, 620.9ms\n",
      "Speed: 0.0ms preprocess, 620.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 1 face_without_glasses, 650.0ms\n",
      "Speed: 0.0ms preprocess, 650.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 697.9ms\n",
      "Speed: 0.0ms preprocess, 697.9ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 620.3ms\n",
      "Speed: 0.0ms preprocess, 620.3ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 650.3ms\n",
      "Speed: 0.0ms preprocess, 650.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 633.8ms\n",
      "Speed: 0.0ms preprocess, 633.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 616.7ms\n",
      "Speed: 0.0ms preprocess, 616.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 583.1ms\n",
      "Speed: 0.0ms preprocess, 583.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 605.7ms\n",
      "Speed: 13.8ms preprocess, 605.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "def calculate_ear(eye_landmarks):\n",
    "    A = ((eye_landmarks[1][0] - eye_landmarks[5][0]) ** 2 + (eye_landmarks[1][1] - eye_landmarks[5][1]) ** 2) ** 0.5\n",
    "    B = ((eye_landmarks[2][0] - eye_landmarks[4][0]) ** 2 + (eye_landmarks[2][1] - eye_landmarks[4][1]) ** 2) ** 0.5\n",
    "    C = ((eye_landmarks[0][0] - eye_landmarks[3][0]) ** 2 + (eye_landmarks[0][1] - eye_landmarks[3][1]) ** 2) ** 0.5\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]  # P1=33, P2=160, P3=158, P4=133, P5=153, P6=144\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # P1=362, P2=385, P3=387, P4=263, P5=373, P6=380\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Fehler beim Ã–ffnen der Kamera\")\n",
    "    exit()\n",
    "\n",
    "detected_object = None\n",
    "blink_count = 0\n",
    "last_blink_time = time.time()\n",
    "no_blink_start_time = time.time()\n",
    "last_glasses_check_time = time.time()\n",
    "glasses_check_interval = 5\n",
    "treshhold = 0.15\n",
    "\n",
    "# def detect_glasses(frame):\n",
    "#     results = model(frame, conf=0.4)\n",
    "#     detected_objects = results[0].boxes.cls\n",
    "#     if len(detected_objects) == 0:\n",
    "#         return 'no_detection'\n",
    "#     else:\n",
    "#         for detected_object in detected_objects:\n",
    "#             if detected_object.item() == 0:\n",
    "#                 return 'face_with_glasses'\n",
    "#             elif detected_object.item() == 1:\n",
    "#                 return 'face_without_glasses'\n",
    "#             else:\n",
    "#                 return 'no_object'\n",
    "\n",
    "def detect_glasses(frame):\n",
    "    results = model(frame, conf=0.4)\n",
    "    detected_objects = results[0].boxes\n",
    "\n",
    "    if len(detected_objects) == 0:\n",
    "        return 'no_detection'\n",
    "    else:\n",
    "        closest_object = None\n",
    "        max_area = 0\n",
    "\n",
    "        for detected_object in detected_objects:\n",
    "            box = detected_object.xyxy[0]\n",
    "            area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                closest_object = detected_object\n",
    "\n",
    "        if closest_object:\n",
    "            if closest_object.cls.item() == 0:\n",
    "                return 'face_with_glasses'\n",
    "            elif closest_object.cls.item() == 1:\n",
    "                return 'face_without_glasses'\n",
    "            else:\n",
    "                return 'no_object'\n",
    "        else:\n",
    "            return 'no_object'\n",
    "\n",
    "def detect_blinks(frame):\n",
    "    global blink_count, last_blink_time, treshhold\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            left_eye_landmarks = [(face_landmarks.landmark[idx].x * frame.shape[1], \n",
    "                                   face_landmarks.landmark[idx].y * frame.shape[0]) for idx in LEFT_EYE]\n",
    "            right_eye_landmarks = [(face_landmarks.landmark[idx].x * frame.shape[1], \n",
    "                                    face_landmarks.landmark[idx].y * frame.shape[0]) for idx in RIGHT_EYE]\n",
    "\n",
    "            left_ear = calculate_ear(left_eye_landmarks)\n",
    "            right_ear = calculate_ear(right_eye_landmarks)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            # for idx in LEFT_EYE + RIGHT_EYE:\n",
    "            #     x = int(face_landmarks.landmark[idx].x * frame.shape[1])\n",
    "            #     y = int(face_landmarks.landmark[idx].y * frame.shape[0])\n",
    "            #     cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "\n",
    "            if ear < treshhold:\n",
    "                cv2.putText(frame, \"Blinking\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                blink_count += 1\n",
    "                last_blink_time = time.time()\n",
    "\n",
    "    if time.time() - last_blink_time > 10:\n",
    "        cv2.putText(frame, \"Not allowed to drive\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "def process_frame():\n",
    "    global last_glasses_check_time, treshhold\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Fehler beim Erfassen des Frames\")\n",
    "            break\n",
    "\n",
    "        detect_blinks(frame)\n",
    "        \n",
    "        current_time = time.time()\n",
    "        if current_time - last_glasses_check_time > glasses_check_interval:\n",
    "            print(f\"Glasses Detection\")\n",
    "            last_glasses_check_time = current_time\n",
    "\n",
    "            glasses_status = detect_glasses(frame)\n",
    "            if glasses_status == 'face_with_glasses':\n",
    "                treshhold = 0.05 \n",
    "            elif glasses_status == 'face_without_glasses':\n",
    "                treshhold = 0.20 \n",
    "            else:\n",
    "                treshhold = 0.15\n",
    "\n",
    "        cv2.imshow('YOLOv8 Predictions and Eye Landmarks', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "processing_thread = threading.Thread(target=process_frame)\n",
    "processing_thread.start()\n",
    "processing_thread.join()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leo\\Desktop\\AI\\fairness_demonstator\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 815.2ms\n",
      "Speed: 18.7ms preprocess, 815.2ms inference, 24.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 725.0ms\n",
      "Speed: 3.2ms preprocess, 725.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 602.7ms\n",
      "Speed: 0.0ms preprocess, 602.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 633.4ms\n",
      "Speed: 0.0ms preprocess, 633.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 639.7ms\n",
      "Speed: 0.0ms preprocess, 639.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 607.1ms\n",
      "Speed: 0.0ms preprocess, 607.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 640.7ms\n",
      "Speed: 3.0ms preprocess, 640.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 651.8ms\n",
      "Speed: 0.0ms preprocess, 651.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 749.0ms\n",
      "Speed: 0.0ms preprocess, 749.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 721.8ms\n",
      "Speed: 0.0ms preprocess, 721.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 651.8ms\n",
      "Speed: 0.0ms preprocess, 651.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 577.7ms\n",
      "Speed: 0.0ms preprocess, 577.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 602.7ms\n",
      "Speed: 0.0ms preprocess, 602.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 595.7ms\n",
      "Speed: 0.0ms preprocess, 595.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 600.2ms\n",
      "Speed: 0.0ms preprocess, 600.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 599.9ms\n",
      "Speed: 0.0ms preprocess, 599.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 602.5ms\n",
      "Speed: 0.0ms preprocess, 602.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 634.2ms\n",
      "Speed: 14.7ms preprocess, 634.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 583.5ms\n",
      "Speed: 12.2ms preprocess, 583.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 624.5ms\n",
      "Speed: 0.0ms preprocess, 624.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 596.5ms\n",
      "Speed: 0.6ms preprocess, 596.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "def calculate_ear(eye_landmarks):\n",
    "    A = ((eye_landmarks[1][0] - eye_landmarks[5][0]) ** 2 + (eye_landmarks[1][1] - eye_landmarks[5][1]) ** 2) ** 0.5\n",
    "    B = ((eye_landmarks[2][0] - eye_landmarks[4][0]) ** 2 + (eye_landmarks[2][1] - eye_landmarks[4][1]) ** 2) ** 0.5\n",
    "    C = ((eye_landmarks[0][0] - eye_landmarks[3][0]) ** 2 + (eye_landmarks[0][1] - eye_landmarks[3][1]) ** 2) ** 0.5\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=2, \n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]  # P1=33, P2=160, P3=158, P4=133, P5=153, P6=144\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # P1=362, P2=385, P3=387, P4=263, P5=373, P6=380\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Fehler beim Ã–ffnen der Kamera\")\n",
    "    exit()\n",
    "\n",
    "detected_object = None\n",
    "blink_count = 0\n",
    "last_blink_time = time.time()\n",
    "no_blink_start_time = time.time()\n",
    "last_glasses_check_time = time.time()\n",
    "glasses_check_interval = 5\n",
    "treshhold = 0.15\n",
    "\n",
    "def detect_glasses(frame):\n",
    "    results = model(frame, conf=0.4)\n",
    "    detected_objects = results[0].boxes\n",
    "\n",
    "    if len(detected_objects) == 0:\n",
    "        return 'no_detection'\n",
    "    else:\n",
    "        closest_object = None\n",
    "        max_area = 0\n",
    "\n",
    "        for detected_object in detected_objects:\n",
    "            box = detected_object.xyxy[0]\n",
    "            area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                closest_object = detected_object\n",
    "\n",
    "        if closest_object:\n",
    "            if closest_object.cls.item() == 0:\n",
    "                return 'face_with_glasses'\n",
    "            elif closest_object.cls.item() == 1:\n",
    "                return 'face_without_glasses'\n",
    "            else:\n",
    "                return 'no_object'\n",
    "        else:\n",
    "            return 'no_object'\n",
    "\n",
    "def detect_blinks(frame):\n",
    "    global blink_count, last_blink_time, treshhold\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        closest_face_landmarks = None\n",
    "        max_area = 0\n",
    "\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            x_min = min([landmark.x for landmark in face_landmarks.landmark])\n",
    "            y_min = min([landmark.y for landmark in face_landmarks.landmark])\n",
    "            x_max = max([landmark.x for landmark in face_landmarks.landmark])\n",
    "            y_max = max([landmark.y for landmark in face_landmarks.landmark])\n",
    "            area = (x_max - x_min) * (y_max - y_min)\n",
    "\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                closest_face_landmarks = face_landmarks\n",
    "\n",
    "        if closest_face_landmarks:\n",
    "            left_eye_landmarks = [(closest_face_landmarks.landmark[idx].x * frame.shape[1], \n",
    "                                   closest_face_landmarks.landmark[idx].y * frame.shape[0]) for idx in LEFT_EYE]\n",
    "            right_eye_landmarks = [(closest_face_landmarks.landmark[idx].x * frame.shape[1], \n",
    "                                    closest_face_landmarks.landmark[idx].y * frame.shape[0]) for idx in RIGHT_EYE]\n",
    "\n",
    "            left_ear = calculate_ear(left_eye_landmarks)\n",
    "            right_ear = calculate_ear(right_eye_landmarks)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            if ear < treshhold:\n",
    "                cv2.putText(frame, \"Blinking\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                blink_count += 1\n",
    "                last_blink_time = time.time()\n",
    "\n",
    "    if time.time() - last_blink_time > 10:\n",
    "        cv2.putText(frame, \"Not allowed to drive\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "def process_frame():\n",
    "    global last_glasses_check_time, treshhold\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Fehler beim Erfassen des Frames\")\n",
    "            break\n",
    "\n",
    "        detect_blinks(frame)\n",
    "        \n",
    "        current_time = time.time()\n",
    "        if current_time - last_glasses_check_time > glasses_check_interval:\n",
    "            print(f\"Glasses Detection\")\n",
    "            last_glasses_check_time = current_time\n",
    "\n",
    "            glasses_status = detect_glasses(frame)\n",
    "            if glasses_status == 'face_with_glasses':\n",
    "                treshhold = 0.01 \n",
    "            elif glasses_status == 'face_without_glasses':\n",
    "                treshhold = 0.20 \n",
    "            else:\n",
    "                treshhold = 0.15\n",
    "\n",
    "        cv2.imshow('YOLOv8 Predictions and Eye Landmarks', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "processing_thread = threading.Thread(target=process_frame)\n",
    "processing_thread.start()\n",
    "processing_thread.join()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ear(eye_landmarks):\n",
    "    A = ((eye_landmarks[1][0] - eye_landmarks[5][0]) ** 2 + (eye_landmarks[1][1] - eye_landmarks[5][1]) ** 2) ** 0.5\n",
    "    B = ((eye_landmarks[2][0] - eye_landmarks[4][0]) ** 2 + (eye_landmarks[2][1] - eye_landmarks[4][1]) ** 2) ** 0.5\n",
    "    C = ((eye_landmarks[0][0] - eye_landmarks[3][0]) ** 2 + (eye_landmarks[0][1] - eye_landmarks[3][1]) ** 2) ** 0.5\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=2,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]  # P1=33, P2=160, P3=158, P4=133, P5=153, P6=144\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # P1=362, P2=385, P3=387, P4=263, P5=373, P6=380\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Fehler beim Ã–ffnen der Kamera\")\n",
    "    exit()\n",
    "\n",
    "detected_object = None\n",
    "blink_count = 0\n",
    "last_blink_time = time.time()\n",
    "no_blink_start_time = time.time()\n",
    "last_glasses_check_time = time.time()\n",
    "glasses_check_interval = 5\n",
    "treshhold = 0.15\n",
    "\n",
    "def detect_glasses(frame):\n",
    "    results = model(frame, conf=0.4)\n",
    "    detected_objects = results[0].boxes\n",
    "\n",
    "    if len(detected_objects) == 0:\n",
    "        return 'no_detection'\n",
    "    else:\n",
    "        closest_object = None\n",
    "        max_area = 0\n",
    "\n",
    "        for detected_object in detected_objects:\n",
    "            box = detected_object.xyxy[0]\n",
    "            area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                closest_object = detected_object\n",
    "\n",
    "        if closest_object:\n",
    "            if closest_object.cls.item() == 0:\n",
    "                return 'face_with_glasses'\n",
    "            elif closest_object.cls.item() == 1:\n",
    "                return 'face_without_glasses'\n",
    "            else:\n",
    "                return 'no_object'\n",
    "        else:\n",
    "            return 'no_object'\n",
    "\n",
    "\n",
    "processing_thread = threading.Thread(target=process_frame)\n",
    "processing_thread.start()\n",
    "processing_thread.join()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrator save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leo\\Desktop\\AI\\fairness_demonstator\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 886.3ms\n",
      "Speed: 15.6ms preprocess, 886.3ms inference, 22.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 616.1ms\n",
      "Speed: 3.2ms preprocess, 616.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 619.3ms\n",
      "Speed: 2.0ms preprocess, 619.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 579.4ms\n",
      "Speed: 1.2ms preprocess, 579.4ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 634.1ms\n",
      "Speed: 2.9ms preprocess, 634.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 605.0ms\n",
      "Speed: 3.0ms preprocess, 605.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 644.5ms\n",
      "Speed: 2.0ms preprocess, 644.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 (no detections), 640.3ms\n",
      "Speed: 4.3ms preprocess, 640.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 651.7ms\n",
      "Speed: 2.0ms preprocess, 651.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 621.6ms\n",
      "Speed: 2.1ms preprocess, 621.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 624.5ms\n",
      "Speed: 3.0ms preprocess, 624.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 602.0ms\n",
      "Speed: 2.0ms preprocess, 602.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 619.9ms\n",
      "Speed: 2.0ms preprocess, 619.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 609.0ms\n",
      "Speed: 6.0ms preprocess, 609.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 2 face_without_glassess, 603.7ms\n",
      "Speed: 2.0ms preprocess, 603.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 648.8ms\n",
      "Speed: 2.0ms preprocess, 648.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 656.0ms\n",
      "Speed: 3.5ms preprocess, 656.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_with_glasses, 602.5ms\n",
      "Speed: 4.0ms preprocess, 602.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 2 face_with_glassess, 592.4ms\n",
      "Speed: 6.0ms preprocess, 592.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 667.1ms\n",
      "Speed: 4.1ms preprocess, 667.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Glasses Detection\n",
      "\n",
      "0: 480x640 1 face_without_glasses, 606.8ms\n",
      "Speed: 4.8ms preprocess, 606.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "import mediapipe as mp\n",
    "\n",
    "def calculate_ear(eye_landmarks):\n",
    "    A = ((eye_landmarks[1][0] - eye_landmarks[5][0]) ** 2 + (eye_landmarks[1][1] - eye_landmarks[5][1]) ** 2) ** 0.5\n",
    "    B = ((eye_landmarks[2][0] - eye_landmarks[4][0]) ** 2 + (eye_landmarks[2][1] - eye_landmarks[4][1]) ** 2) ** 0.5\n",
    "    C = ((eye_landmarks[0][0] - eye_landmarks[3][0]) ** 2 + (eye_landmarks[0][1] - eye_landmarks[3][1]) ** 2) ** 0.5\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=2, \n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]  # P1=33, P2=160, P3=158, P4=133, P5=153, P6=144\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # P1=362, P2=385, P3=387, P4=263, P5=373, P6=380\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Fehler beim Ã–ffnen der Kamera\")\n",
    "    exit()\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'XVID'), 20, (frame_width, frame_height))\n",
    "\n",
    "detected_object = None\n",
    "blink_count = 0\n",
    "last_blink_time = time.time()\n",
    "no_blink_start_time = time.time()\n",
    "last_glasses_check_time = time.time()\n",
    "glasses_check_interval = 5\n",
    "treshhold = 0.15\n",
    "\n",
    "def detect_glasses(frame):\n",
    "    results = model(frame, conf=0.4)\n",
    "    detected_objects = results[0].boxes\n",
    "\n",
    "    if len(detected_objects) == 0:\n",
    "        return 'no_detection'\n",
    "    else:\n",
    "        closest_object = None\n",
    "        max_area = 0\n",
    "\n",
    "        for detected_object in detected_objects:\n",
    "            box = detected_object.xyxy[0]\n",
    "            area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                closest_object = detected_object\n",
    "\n",
    "        if closest_object:\n",
    "            if closest_object.cls.item() == 0:\n",
    "                return 'face_with_glasses'\n",
    "            elif closest_object.cls.item() == 1:\n",
    "                return 'face_without_glasses'\n",
    "            else:\n",
    "                return 'no_object'\n",
    "        else:\n",
    "            return 'no_object'\n",
    "\n",
    "def detect_blinks(frame):\n",
    "    global blink_count, last_blink_time, treshhold\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        closest_face_landmarks = None\n",
    "        max_area = 0\n",
    "\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            x_min = min([landmark.x for landmark in face_landmarks.landmark])\n",
    "            y_min = min([landmark.y for landmark in face_landmarks.landmark])\n",
    "            x_max = max([landmark.x for landmark in face_landmarks.landmark])\n",
    "            y_max = max([landmark.y for landmark in face_landmarks.landmark])\n",
    "            area = (x_max - x_min) * (y_max - y_min)\n",
    "\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                closest_face_landmarks = face_landmarks\n",
    "\n",
    "        if closest_face_landmarks:\n",
    "            left_eye_landmarks = [(closest_face_landmarks.landmark[idx].x * frame.shape[1], \n",
    "                                   closest_face_landmarks.landmark[idx].y * frame.shape[0]) for idx in LEFT_EYE]\n",
    "            right_eye_landmarks = [(closest_face_landmarks.landmark[idx].x * frame.shape[1], \n",
    "                                    closest_face_landmarks.landmark[idx].y * frame.shape[0]) for idx in RIGHT_EYE]\n",
    "\n",
    "            left_ear = calculate_ear(left_eye_landmarks)\n",
    "            right_ear = calculate_ear(right_eye_landmarks)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            if ear < treshhold:\n",
    "                cv2.putText(frame, \"Blinking\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                blink_count += 1\n",
    "                last_blink_time = time.time()\n",
    "\n",
    "    if time.time() - last_blink_time > 10:\n",
    "        cv2.putText(frame, \"Not allowed to drive\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "def process_frame():\n",
    "    global last_glasses_check_time, treshhold\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Fehler beim Erfassen des Frames\")\n",
    "            break\n",
    "\n",
    "        detect_blinks(frame)\n",
    "        \n",
    "        current_time = time.time()\n",
    "        if current_time - last_glasses_check_time > glasses_check_interval:\n",
    "            print(f\"Glasses Detection\")\n",
    "            last_glasses_check_time = current_time\n",
    "\n",
    "            glasses_status = detect_glasses(frame)\n",
    "            if glasses_status == 'face_with_glasses':\n",
    "                treshhold = 0.05 \n",
    "            elif glasses_status == 'face_without_glasses':\n",
    "                treshhold = 0.20 \n",
    "            else:\n",
    "                treshhold = 0.15\n",
    "\n",
    "        cv2.imshow('YOLOv8 Predictions and Eye Landmarks', frame)\n",
    "        out.write(frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "processing_thread = threading.Thread(target=process_frame)\n",
    "processing_thread.start()\n",
    "processing_thread.join()\n",
    "\n",
    "cap.release()\n",
    "out.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
